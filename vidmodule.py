#!/usr/bin/env python3

import cv2
import numpy as np

# TODO:
# - improve foreground mask with MOG subtraction
# - standardize detectFrame functions to return:
#     array of x/y coords of centers of detected objects
#     frame that has some sort of labeling of detected objects
# - maybe? integrate unique object tracking
#     would involve using vectors to determine whether object moves too far

DEBUG = False

# for fixing openCV y axis
def fixCoord(val, max):
    newVal = max - val
    return newVal

def getBlobDetect():
    # Set up blob detector
    params = cv2.SimpleBlobDetector_Params()
    params.minThreshold = 30
    params.maxThreshold = 256
    params.filterByArea = True
    params.minArea = 1000
    params.maxArea = 10000
    params.filterByCircularity = False
    params.filterByConvexity = False
    params.filterByInertia = True

    detector = cv2.SimpleBlobDetector_create(params)

    return detector


def processImg(im):
    # im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)

    # remove shadows
    #   blur to remove noise
    frame = cv2.GaussianBlur(im, (3, 3), 0)

    #   threshold to remove shadows
    grayMin = 0
    grayMax = 125
    mask = cv2.inRange(frame, grayMin, grayMax)
    res = cv2.bitwise_and(frame, frame, mask = mask)

    if DEBUG:
        cv2.imshow("masked image", res)
        cv2.waitKey(1)

    res = cv2.dilate(res, None, iterations = 1)
    res = 255-res
    ret,thresh_img = cv2.threshold(res,250,255,cv2.THRESH_BINARY)

    if DEBUG:
        cv2.imshow("binary image", res)
        cv2.waitKey(1)

    return im

def processMask(mask):
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))

    # Fill any small holes
    closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    # Remove noise
    opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel)

    # Dilate to merge adjacent blobs
    dilation = cv2.dilate(opening, kernel, iterations = 2)

    return dilation

# detects objects in frame using blob detector
# returns list of keypoints, as well as image with drawn keypoints
def detectFrame_Blob(detector, im):
    keypoints = detector.detect(im)

    centroids = []
    for keypoint in keypoints:
        #     x = keypoint.pt[0]
        #     y = keypoint.pt[1]
        centroid = (keypoint.pt[0], keypoint.pt[1])
        centroids.append(centroid)

    # cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob
    im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

    return im_with_keypoints, centroids
    # return im_with_keypoints, keypoints

# for use with the fgMask generated by MOG background subtraction
# returns list of centroid coordinates + image with centroids drawn on it
def detectFrame_MOG(fgMask, im):
    contours, hierarchy = cv2.findContours(fgMask, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
    try:
        hierarchy = hierarchy[0]

    except:
        hierarchy = []

    cont_min_width = 30
    cont_max_width = 300
    cont_min_height = 30
    cont_max_height = 300
    centroids = []

    for contour, hier in zip(contours, hierarchy):
        (x, y, w, h) = cv2.boundingRect(contour)

        if w > cont_min_width and w < cont_max_width and h > cont_min_height and h < cont_max_height:
            cv2.rectangle(im, (x,y), (x+w,y+h), (255, 0, 0), 1)

            # centroid of contour
            x1 = w/2
            y1 = h/2
            cx = x+x1
            cy = y+y1

            centroid = (cx,cy)
            centroids.append(centroid)
            # Draw the circle of Centroid
            cv2.circle(im,(int(cx),int(cy)),2,(0,0,255),-1)

    return im, centroids

# get dimensions of openCV video capture
def getVidBounds(cap):
    vidWidth  = int(cap.get(3))
    vidHeight = int(cap.get(4))
    return vidWidth, vidHeight

def rescale_frame(frame, percent=75):
    width = int(frame.shape[1] * percent/ 100)
    height = int(frame.shape[0] * percent/ 100)
    dim = (width, height)
    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)


# if __name__ == "__main__":
#     detector = getBlobDetect()
#
#     # read frames from VideoCapture
#     cap = cv2.VideoCapture("oneperson.mp4")
#
#     if (cap.isOpened() == False):
#         print("error opening file")
#     else:
#         if DEBUG:
#             print("width = "  + str(int(cap.get(3))))
#             print("height = " + str(int(cap.get(4))))
#
#     while (cap.isOpened()):
#         ret, im = cap.read()
#         if ret == True:
#             im = processImg(im)
#             im_with_keypoints, keypoints = detectFrame(detector, im)
#             cv2.imshow("Keypoints", im_with_keypoints)
#             cv2.waitKey(1)
#
#             if cv2.waitKey(25) & 0xFF == ord('q'):
#                 break
#
#     cap.release()
#     cv2.destroyAllWindows()
