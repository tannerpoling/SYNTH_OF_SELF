1. DONE install python packages
  - DONE opencv
  - DONE synth

2. DONE basic synth manipulation
  - DONE multithreading for multiple synths
  - DONE vary pitch with time / changing variable
    - make an iterable that only returns one variable
    - have this variable be updated by opencv processing a frame
    - working on making a varying synth that doesn't pop/click
      - have a sine wave going for a while, then make a ramp up
        - have sinusoid(base freq) * some gain [ just do what chirp example does ]
        - grab current value of gain, use line() to make ramp from there to end value
  - DONE make pitch adjustment more robust\
    - upper / lower bounds of pitch
    - rate of change bounds
  - DONE vary modulation with time / changing variable

3. DONE basic opencv object detection
  - big objects / fast recognition
    - YOLO?
      - wayyyyy overkill
    - assign position / center coordinate
    - export numerical value
      - try drawing on screen
  - idea of tracking unique objects over time?
  - maybe try adapting calibration work from APL
    - have a script that runs, adjusts parameters to get "best" detection,
      then saves that to some sort of config file that can be loaded in
      and run on the original video

4. DONE opencv -> synth (one object)
  - take value of 1 object position -> control synth
    - probably just do biggest object in view?
  - vidmodule detects, returns keypoints. needs to be passed to synthmodule
    - synthmodule then checks number of current synths vs number of blobs before starting any new synths?
    - need some sort of update method in synthmodule that runs every frame, updates pitch and mod of each synth

5. DONE opencv -> synth (multiple object)
  - calibrate termination criteria for multiple objects
  - each one controls a separate synth

5a. Improve code
  - unique object tracking
    - mapping unique objects to an assigned synth, not just 4 constantly running synths
  - DONE more robust tracking algo (not just using blob detection)
    - MOG background subtraction for easier blob detection
  - (kind of) DONE visualizations
    - heatmap of blob locations
    - harmony response
      - initial goal: green circle on screen when in harmony
  - (maybe) trying smoother pitch transitions
    - syncing image processing with making ramps to smoothly transition pitch
      - need to enforce time delay between frames being processed
      
5b. Improve sounds
  - add harmonics to synths to make them more pleasant to listen to
    - could look up harmonics of common instruments, voices etc
    - unsure whether to make more synths in audiolazy or just pipe audio thru some sort of filter
 
6. Harmony detection (for harmony-based)
  - audiolazy has functions to convert frequencies to scientific pitch notations
  - could be combined with packages that go from pitch notation -> chords
  
7. Visuals (harmony-based)
  - DONE TouchDesigner communication with synth of self
  - make some sort of basic viz
    - think of a topographic map? people in room become "hills"
    - harmony state used as a flag to enable more... illustrious visuals?

7. get feedback (for harmony-based)
  - dxarts profs
  - students
  - art people (especially the intimidating ones)

8. get a demo together (harmony-based)
8a. DONE demo (horror-based)

9. propose to art people / find a space for an exhibit
